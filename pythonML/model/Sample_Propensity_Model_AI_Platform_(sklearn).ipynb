{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sample Propensity Model - AI Platform (sklearn).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3qCJBaKz2Sc",
        "colab_type": "text"
      },
      "source": [
        "**Disclaimer:** The following code demonstrates a sample model creation with AI Platform, based on GA-BQ export dataset. This is meant for inspiration only. We expect analysts/data scientists to identify the right set of features to create retargeted audiences based on their business needs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YCj6kfhpwFs",
        "colab_type": "text"
      },
      "source": [
        "#Local Setup "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ejBPbKSlpMq",
        "colab_type": "text"
      },
      "source": [
        "Cloud AI Platform model versions need to be compatible across the Python interpreter, scikit-learn version, and AI Platform ML runtime. To maintain consistency, we'll be using Python 3.7, scikit-learn (0.20.4) and ML runtime 1.15."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0CXs9NXkMKJ",
        "colab_type": "text"
      },
      "source": [
        "As the default interpreter for Colab is Python 3.6, we'll be using a local runtime. \n",
        "Open a shell on your system and follow the instructions - \n",
        "1. Create & activate a virtualenv with Python 3.7, e.g. \n",
        "```\n",
        "python3.7 -m virtualenv venv && source venv/bin/activate\n",
        "```\n",
        "2. Type\n",
        "```\n",
        "pip install jupyter_http_over_ws\n",
        "```\n",
        "3. Type\n",
        "``` \n",
        "jupyter serverextension enable --py jupyter_http_over_ws\n",
        "```\n",
        "4. Start local server:\n",
        "``` \n",
        "jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' --port=8888 --NotebookApp.port_retries=0\n",
        "```\n",
        "5. Copy the server URL and paste in Backend URL field. ('Connect to a local runtime' on the top left)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl8GH6f6mil3",
        "colab_type": "text"
      },
      "source": [
        "Check if you are using python3.7 and update gcloud SDK. (Install if needed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa88rMU-lorG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python --version && gcloud components update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V68M0kJJmpLr",
        "colab_type": "text"
      },
      "source": [
        "Install requirements and login into the right email and project\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgGHc2JPmQ2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install scikit-learn==0.20.4 google-cloud-bigquery pandas numpy google-api-python-client"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yikngipWnaE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gcloud init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kniy_ygvnVHN",
        "colab_type": "text"
      },
      "source": [
        "# Update Params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKhw2r-HnAL3",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "GCP_PROJECT_ID = \"\" #@param {type:\"string\"}\n",
        "BQ_DATASET = \"\" #@param {type:\"string\"}\n",
        "REGION = \"us-central1\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqii2t84nEtH",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Enter Model Parameters\n",
        "GCS_MODEL_DIR = \"gs://\" #@param {type: \"string\"}\n",
        "MODEL_NAME = \"\" #@param {type:\"string\"}\n",
        "VERSION_NAME = \"\" #@param {type: \"string\"}\n",
        "FRAMEWORK = \"SCIKIT_LEARN\" #@param [\"SCIKIT_LEARN\", \"TENSORFLOW\", \"XGBOOST\"]\n",
        "\n",
        "if GCS_MODEL_DIR[-1] != '/':\n",
        "  GCS_MODEL_DIR = GCS_MODEL_DIR + '/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2EMwjp9sSq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from google.cloud import bigquery\n",
        "client = bigquery.Client(project=GCP_PROJECT_ID)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SpfWUb0nuOW",
        "colab_type": "text"
      },
      "source": [
        "# Generate and load sample GA dataset\n",
        "Based on an anonymized public GA dataset. <br>\n",
        "We are creating sample training and test datasets to use as input for the propensity model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yWmZoLWntqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_query = \"\"\"\n",
        "WITH sample_raw_data AS (\n",
        "  SELECT CAST(CEIL(RAND() * 100) AS INT64) AS clientId, * EXCEPT (clientId) FROM `bigquery-public-data.google_analytics_sample.ga_sessions_20170801` LIMIT 1000\n",
        "),\n",
        "visit_data AS (\n",
        "  SELECT clientId, SUM(totals.visits) AS all_visits, CAST(ROUND(RAND() * 1) AS INT64) AS converted\n",
        "  FROM sample_raw_data\n",
        "  GROUP BY clientId\n",
        ")\n",
        "SELECT *\n",
        "FROM visit_data\n",
        "\"\"\"\n",
        "df = client.query(my_query).to_dataframe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TAJXgg8n1_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaxnoIKZn8IG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data_size = math.ceil(df.shape[0] * 0.7)\n",
        "training_data = df[:training_data_size]\n",
        "test_data = df[training_data_size:]\n",
        "training_data.to_csv('training.csv', index=False)\n",
        "test_data.to_csv('test.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AC3ORu3oAtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BQ_TABLE_TRAINING = BQ_DATASET+\".training_data\"\n",
        "BQ_TABLE_TEST = BQ_DATASET+\".test_data\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U84qjNlQoCEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!bq load --project_id $GCP_PROJECT_ID --autodetect --source_format='CSV' $BQ_TABLE_TRAINING training.csv\n",
        "!bq load --project_id $GCP_PROJECT_ID --autodetect --source_format='CSV' $BQ_TABLE_TEST test.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wmVfhvXoDPD",
        "colab_type": "text"
      },
      "source": [
        "# Load Training Data from BQ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLTdZkb4oFAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_query = \"SELECT * FROM `{0}.{1}`\".format(GCP_PROJECT_ID,BQ_TABLE_TRAINING)\n",
        "training = client.query(my_query).to_dataframe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA1ftoyHoIou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eG3ubcOoKLH",
        "colab_type": "text"
      },
      "source": [
        "# Train & Test the model (Simple) - Logistic Regression model\n",
        "We are using a Logistic Regression model which predicts if the user will convert. <br>\n",
        "The model output is a 0 (false) or 1 (true) for each user."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJkFVZzKoNdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from googleapiclient import discovery\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVQKjxBAoQmD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features, labels = training[[\"all_visits\"]], training[\"converted\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2, random_state=1)\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRdFzAD9oVWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = LogisticRegression(penalty='l2')\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred = lr.predict(X_test)\n",
        "y_pred[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuE8dfqptqfh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjMIbNO2ocsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNIwpm9JyXVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr.predict_proba(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wmnt2hKtovEe",
        "colab_type": "text"
      },
      "source": [
        "# Package & Upload Model to GCP (Simple)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il8GAjH9owYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('model.pkl', 'wb') as f:\n",
        "  pickle.dump(lr,f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73rXj8UqtKJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! gsutil cp model.pkl $GCS_MODEL_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1azfdCuaozg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! gcloud config set project $GCP_PROJECT_ID\n",
        "! gcloud ai-platform models create $MODEL_NAME --regions $REGION\n",
        "! gcloud ai-platform versions create $VERSION_NAME --model $MODEL_NAME --origin $GCS_MODEL_DIR --runtime-version=1.15 --framework $FRAMEWORK --python-version=3.7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqAcETzCYcf6",
        "colab_type": "text"
      },
      "source": [
        "# Train, Test & Upload the model (Advanced) - Logistic Regression model with probability outputs\n",
        "\n",
        "We are using a Logistic Regression model to predict if the user will convert. <br>\n",
        "The model output is [class_label, probability], e.g. [1, 0.95]. That is, there's 95% chance the user will convert.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztQroSafYkOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile predictor.py\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class MyPredictor(object):\n",
        "  def __init__(self, model):\n",
        "    self._model = model\n",
        "\n",
        "  def predict(self, instances, **kwargs):\n",
        "    inputs = np.asarray(instances)\n",
        "    probabilities = self._model.predict_proba(inputs).tolist()\n",
        "    outputs = [[p.index(max(p)), max(p)] for p in probabilities] #label, probability\n",
        "    return outputs\n",
        "\n",
        "  @classmethod\n",
        "  def from_path(cls, model_dir):\n",
        "    model_path = os.path.join(model_dir, 'model.pkl')\n",
        "    with open(model_path, 'rb') as f:\n",
        "      model = pickle.load(f)\n",
        "\n",
        "    return cls(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp1pStwoZKs0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile setup.py\n",
        "from setuptools import setup\n",
        "\n",
        "setup(\n",
        "    name='my_custom_code',\n",
        "    version='0.1',\n",
        "    scripts=['predictor.py'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHoHhKGsZmid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GCS_CUSTOM_ROUTINE_PATH = GCS_MODEL_DIR +\"my_custom_code-0.1.tar.gz\"\n",
        "GCS_MODEL_PATH = GCS_MODEL_DIR + \"model/\"\n",
        "ADVANCED_VERSION_NAME = VERSION_NAME + \"_2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP-yQ9TgaYMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python setup.py sdist --formats=gztar\n",
        "!gsutil cp model.pkl $GCS_MODEL_PATH\n",
        "!gsutil cp ./dist/my_custom_code-0.1.tar.gz $GCS_CUSTOM_ROUTINE_PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKBEFRgB9RL-",
        "colab_type": "text"
      },
      "source": [
        "If model not created, create the model by uncommenting the first 2 lines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYJ_HOqHarks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!gcloud config set project $GCP_PROJECT_ID\n",
        "#!gcloud ai-platform models create $MODEL_NAME --regions $REGION\n",
        "!gcloud beta ai-platform versions create $ADVANCED_VERSION_NAME --model $MODEL_NAME --origin $GCS_MODEL_PATH --runtime-version=1.15 --python-version=3.7 --package-uris $GCS_CUSTOM_ROUTINE_PATH --prediction-class predictor.MyPredictor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adpCmo0zuj_w",
        "colab_type": "text"
      },
      "source": [
        "# (OPTIONAL) Testing predictions from the AI Platform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWmihUULupjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_query = \"SELECT * FROM `{0}.{1}`\".format(GCP_PROJECT_ID,BQ_TABLE_TEST)\n",
        "test = client.query(my_query).to_dataframe()\n",
        "features_df = test[\"all_visits\"]\n",
        "features = features_df.values.tolist()\n",
        "features = [[f] for f in features] if len(np.array(features).shape) == 1 else features\n",
        "features[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqKvyGa6d9Gj",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression Model (Simple)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3KicWK8voC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ai_platform = discovery.build(\"ml\", \"v1\")\n",
        "name = 'projects/{}/models/{}/versions/{}'.format(GCP_PROJECT_ID, MODEL_NAME, VERSION_NAME)\n",
        "response = ai_platform.projects().predict(name=name, body={'instances': features}).execute()\n",
        "\n",
        "if 'error' in response:\n",
        "  raise RuntimeError(response['error'])\n",
        "else:\n",
        "  predictions = response['predictions']\n",
        "  print(predictions[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWrI5Mzhv1o3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['predicted'] = predictions\n",
        "test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijJVADoOx7Ow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_score(test['converted'], test['predicted'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5m12mMdyBw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "confusion_matrix(test['converted'], test['predicted'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBgvT_8bdvZN",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression Model with Probabilty Outputs (Advanced)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvvNeZxh4Ai0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ai_platform = discovery.build('ml', 'v1')\n",
        "name = 'projects/{}/models/{}/versions/{}'.format(GCP_PROJECT_ID, MODEL_NAME, ADVANCED_VERSION_NAME)\n",
        "\n",
        "response = ai_platform.projects().predict(name=name, body={'instances': features}).execute()\n",
        "\n",
        "if 'error' in response:\n",
        "  raise RuntimeError(response['error'])\n",
        "else:\n",
        "  predictions = response['predictions']\n",
        "  print(predictions[:5])\n",
        "  test['advanced_labels'] = [p[0] for p in predictions]\n",
        "  test['advanced_probs'] = [p[1] for p in predictions]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "922wCiFd-8xj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5H90eEHkfCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def postprocess_output(df):\n",
        "  df = df[df['advanced_labels'] == 1] #predicted to convert\n",
        "  df['decile'] = pd.qcut(df['advanced_probs'], 10, labels=False, duplicates='drop') \n",
        "  col_mapper = {'decile': 'ga:dimension1',\n",
        "                'clientId': 'ga:userId'}\n",
        "  df_col_names = list(col_mapper.keys())\n",
        "  export_names = [col_mapper[key] for key in df_col_names]\n",
        "  df = df[df_col_names]\n",
        "  df.columns = export_names\n",
        "  return df\n",
        "\n",
        "postprocess_output(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZS8wuvVu11Y",
        "colab_type": "text"
      },
      "source": [
        "# Automation with Modem - Parameter Specification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9cfF5yKvD8h",
        "colab_type": "text"
      },
      "source": [
        "## 1. Select BQ feature rows for model input\n",
        "\n",
        "Say training/test dataset has the schema (in BQ) - 'id', 'feature1', 'feature2'. The model uses 'feature1' & 'feature2', then those are the column names. In this example, only 'all_visits' is used as an input column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRLI4DzKvDfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_INPUT_COL_NAMES = ['all_visits']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vb0wxmyLr06X",
        "colab_type": "text"
      },
      "source": [
        "## 2. Create mapping between BQ schema & Data Import schema\n",
        "The idea here is to think about how the outputs should be mapped before testing and automation. **This will be used in the automation piece.** <br>\n",
        "There are 3 distinct cases - \n",
        "1. Data Import schema includes the **same column from BigQuery** (e.g. clientId) <br>\n",
        "   'clientId': 'ga:userId'\n",
        "2. Data Import schema includes the **model output without any post processing** (e.g. kMeans cluster number, logistic class number) In this case, always use the predicted key as follows - <br>\n",
        "   'predicted': 'ga:dimension1'\n",
        "3. Data Import schema includes the **model output without post processing** (e.g. predict_proba output from logistic regression model) - <br> In this case, the key should be the same as the ***intended post-processed column name*** (say, decile). Check the example above for more details. <br>\n",
        "    'decile':  'ga:dimension2'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA7GjuJ5tmXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#case 2\n",
        "CSV_COLUMN_MAP = {'clientId': 'ga:userId',\n",
        "                  'predicted': 'ga:dimension1'}\n",
        "#case 3\n",
        "CSV_COLUMN_MAP = {'clientId': 'ga:userId',\n",
        "                  'decile': 'ga:dimension2'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp6EH02BlHJN",
        "colab_type": "text"
      },
      "source": [
        "# (OPTIONAL) Automation with Modem - Modifying code to add pre and post processing logic\n",
        "\n",
        "In main.py, you can add additional pre and post processing, at the start of the <code>preprocess_features</code> and <code>postprocess_output functions.</code> <br>\n",
        "(i.e. between the comments <code># -------- Additional lines start here --------</code> and <code># -------- Additional lines end here --------</code>). <br>\n",
        "\n",
        "The design principle to keep in mind is to always **add columns to the output dataframe**, even for intermediate outputs if necessary. See the examples below for inspiration - they are based on the Colab examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPQTMSCgjNIa",
        "colab_type": "text"
      },
      "source": [
        "## Pre-processing Example\n",
        "In this example, we are standardizing the allVisits column before passing it as a model input.\n",
        "\n",
        "```\n",
        "def preprocess_features(df):\n",
        "    # TODO(developer): If needed, add preprocessing logic.\n",
        "    # -------- Additional lines start here -------- \n",
        "    standardize_col = lambda x: (x - np.mean(x))/ np.std(x)\n",
        "    df['allVisits] = df['allVisits'].apply(standardize_col) \n",
        "    # -------- Additional lines end here -------- \n",
        "    selected_df = df[BQ_PREDICTION_FEATURES] \n",
        "    features = selected_df.values.tolist()\n",
        "    features = [[f] for f in features] if len(np.array(features).shape) == 1 else features\n",
        "    return features, df\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj9xh-HpiT_G",
        "colab_type": "text"
      },
      "source": [
        "## Post-processing Example\n",
        "\n",
        "In this example, we are converting a prediction output from a custom prediction routine to a format for GA import. <br>\n",
        "Specifically, we are using the prediction output of [label, probability] to filter users who are likely to convert (label = 1) and use the probabilities to assign deciles. \n",
        "\n",
        "```\n",
        "def postprocess_output(df):\n",
        "    predictions = df['predicted'] \n",
        "    # TODO(developer): If needed, add postprocessing logic. Mostly necessary if using custom prediction routine.\n",
        "    # -------- Additional lines start here -------- \n",
        "    df['advanced_labels'] = [p[0] for p in predictions]\n",
        "    df['advanced_probs'] = [p[1] for p in predictions]\n",
        "    df = df[df['advanced_labels'] == 1] #predicted to convert\n",
        "    df['decile'] = pd.qcut(df['advanced_probs'], 10, labels=False, duplicates='drop')\n",
        "    # -------- Additional lines end here --------  \n",
        "    final_cols = list(CSV_COLUMN_MAP.keys())\n",
        "    df = df[final_cols]\n",
        "    df.columns = [CSV_COLUMN_MAP[bq_col_header] for bq_col_header in final_cols]\n",
        "    return df\n",
        "```"
      ]
    }
  ]
}